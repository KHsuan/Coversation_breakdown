{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-11 09:49:10.608882: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-06-11 09:49:29.587661: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/rds/general/user/yk222/home/anaconda3/envs/tf2_env/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from transformers import BertTokenizer, TFBertModel\n",
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>context</th>\n",
       "      <th>response</th>\n",
       "      <th>overall_score</th>\n",
       "      <th>context_id</th>\n",
       "      <th>context_response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2823</th>\n",
       "      <td>t5</td>\n",
       "      <td>17 weeks if im not mistaken. then the playoffs...</td>\n",
       "      <td>&lt;unk&gt; s&gt;I think it was a college game.</td>\n",
       "      <td>4.00</td>\n",
       "      <td>1</td>\n",
       "      <td>17 weeks if im not mistaken. then the playoffs...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2323</th>\n",
       "      <td>attention_s2s</td>\n",
       "      <td>17 weeks if im not mistaken. then the playoffs...</td>\n",
       "      <td>I think it was a college game and it was a col...</td>\n",
       "      <td>3.75</td>\n",
       "      <td>1</td>\n",
       "      <td>17 weeks if im not mistaken. then the playoffs...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1823</th>\n",
       "      <td>random</td>\n",
       "      <td>17 weeks if im not mistaken. then the playoffs...</td>\n",
       "      <td>I bet they do. They are probably made by engin...</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1</td>\n",
       "      <td>17 weeks if im not mistaken. then the playoffs...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>823</th>\n",
       "      <td>dialogpt</td>\n",
       "      <td>17 weeks if im not mistaken. then the playoffs...</td>\n",
       "      <td>It was a pro game, but still. It was exciting ...</td>\n",
       "      <td>3.75</td>\n",
       "      <td>1</td>\n",
       "      <td>17 weeks if im not mistaken. then the playoffs...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3823</th>\n",
       "      <td>attention_vhred</td>\n",
       "      <td>17 weeks if im not mistaken. then the playoffs...</td>\n",
       "      <td>The coach was the coach and the coach was the ...</td>\n",
       "      <td>3.75</td>\n",
       "      <td>1</td>\n",
       "      <td>17 weeks if im not mistaken. then the playoffs...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3323</th>\n",
       "      <td>gpt3_davinci</td>\n",
       "      <td>17 weeks if im not mistaken. then the playoffs...</td>\n",
       "      <td>It is professional game. What is the highest s...</td>\n",
       "      <td>3.50</td>\n",
       "      <td>1</td>\n",
       "      <td>17 weeks if im not mistaken. then the playoffs...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323</th>\n",
       "      <td>blenderbot-400M-distill</td>\n",
       "      <td>17 weeks if im not mistaken. then the playoffs...</td>\n",
       "      <td>I think it was a college game, but I'm not 100...</td>\n",
       "      <td>4.25</td>\n",
       "      <td>1</td>\n",
       "      <td>17 weeks if im not mistaken. then the playoffs...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4323</th>\n",
       "      <td>ground_truth</td>\n",
       "      <td>17 weeks if im not mistaken. then the playoffs...</td>\n",
       "      <td>222-0. It happened in 1916 when Georgia tech d...</td>\n",
       "      <td>4.50</td>\n",
       "      <td>1</td>\n",
       "      <td>17 weeks if im not mistaken. then the playoffs...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1323</th>\n",
       "      <td>attention_hred</td>\n",
       "      <td>17 weeks if im not mistaken. then the playoffs...</td>\n",
       "      <td>It was Georgia Tech beat Cumberland 222-0</td>\n",
       "      <td>3.50</td>\n",
       "      <td>1</td>\n",
       "      <td>17 weeks if im not mistaken. then the playoffs...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>951</th>\n",
       "      <td>dialogpt</td>\n",
       "      <td>18 holes a games. Seems like a long day.\\nYeah...</td>\n",
       "      <td>i agree. but is a popular sport that a lot of ...</td>\n",
       "      <td>3.75</td>\n",
       "      <td>2</td>\n",
       "      <td>18 holes a games. Seems like a long day.\\nYeah...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        model  \\\n",
       "2823                       t5   \n",
       "2323            attention_s2s   \n",
       "1823                   random   \n",
       "823                  dialogpt   \n",
       "3823          attention_vhred   \n",
       "3323             gpt3_davinci   \n",
       "323   blenderbot-400M-distill   \n",
       "4323             ground_truth   \n",
       "1323           attention_hred   \n",
       "951                  dialogpt   \n",
       "\n",
       "                                                context  \\\n",
       "2823  17 weeks if im not mistaken. then the playoffs...   \n",
       "2323  17 weeks if im not mistaken. then the playoffs...   \n",
       "1823  17 weeks if im not mistaken. then the playoffs...   \n",
       "823   17 weeks if im not mistaken. then the playoffs...   \n",
       "3823  17 weeks if im not mistaken. then the playoffs...   \n",
       "3323  17 weeks if im not mistaken. then the playoffs...   \n",
       "323   17 weeks if im not mistaken. then the playoffs...   \n",
       "4323  17 weeks if im not mistaken. then the playoffs...   \n",
       "1323  17 weeks if im not mistaken. then the playoffs...   \n",
       "951   18 holes a games. Seems like a long day.\\nYeah...   \n",
       "\n",
       "                                               response  overall_score  \\\n",
       "2823             <unk> s>I think it was a college game.           4.00   \n",
       "2323  I think it was a college game and it was a col...           3.75   \n",
       "1823  I bet they do. They are probably made by engin...           3.00   \n",
       "823   It was a pro game, but still. It was exciting ...           3.75   \n",
       "3823  The coach was the coach and the coach was the ...           3.75   \n",
       "3323  It is professional game. What is the highest s...           3.50   \n",
       "323   I think it was a college game, but I'm not 100...           4.25   \n",
       "4323  222-0. It happened in 1916 when Georgia tech d...           4.50   \n",
       "1323          It was Georgia Tech beat Cumberland 222-0           3.50   \n",
       "951   i agree. but is a popular sport that a lot of ...           3.75   \n",
       "\n",
       "      context_id                                   context_response  \n",
       "2823           1  17 weeks if im not mistaken. then the playoffs...  \n",
       "2323           1  17 weeks if im not mistaken. then the playoffs...  \n",
       "1823           1  17 weeks if im not mistaken. then the playoffs...  \n",
       "823            1  17 weeks if im not mistaken. then the playoffs...  \n",
       "3823           1  17 weeks if im not mistaken. then the playoffs...  \n",
       "3323           1  17 weeks if im not mistaken. then the playoffs...  \n",
       "323            1  17 weeks if im not mistaken. then the playoffs...  \n",
       "4323           1  17 weeks if im not mistaken. then the playoffs...  \n",
       "1323           1  17 weeks if im not mistaken. then the playoffs...  \n",
       "951            2  18 holes a games. Seems like a long day.\\nYeah...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_json('../Data/Target/dstc10-topical_eval.json')\n",
    "\n",
    "#### make same context with same context ID\n",
    "df_split = relevance_score(df)\n",
    "df = df_split[[\"model\", \"context\", \"response\", \"overall_score\"]]\n",
    "df = df.sort_values(by=['context'])\n",
    "id = list(range(1, 501)) * 9\n",
    "id.sort()\n",
    "df[\"context_id\"] = id\n",
    "df['context_response'] = df.apply(lambda x: f\"{x['context']} [SEP] {x['response']}\", axis=1)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-11 09:51:52.739102: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22996 MB memory:  -> device: 0, name: Quadro RTX 6000, pci bus id: 0000:a1:00.0, compute capability: 7.5\n",
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFBertModel were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = TFBertModel.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "def tokenizer_with_progress(large_batch):\n",
    "    tokenized_texts = []\n",
    "    for text in tqdm(large_batch, desc=\"Tokenizing\", unit=\"text\"):\n",
    "        tokenized_texts.append(tokenizer(text, return_tensors=\"tf\", padding='max_length', max_length=128, truncation=True))\n",
    "    \n",
    "    embeddings = []\n",
    "    for input_text in tqdm(tokenized_texts, desc=\"Embedding\", unit=\"text\"):\n",
    "        output = model(**input_text)\n",
    "        word_embeddings = output.last_hidden_state\n",
    "        embeddings.append(word_embeddings)\n",
    "\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kendall_tau(preds, train_data):\n",
    "    y_true = train_data.get_label()\n",
    "    tau, _ = kendalltau(y_true, preds)\n",
    "    return 'kendall_tau', 50 * (1 + tau), True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cosine Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenizing: 100%|██████████| 4500/4500 [00:02<00:00, 1503.07text/s]\n",
      "Embedding: 100%|██████████| 4500/4500 [08:36<00:00,  8.72text/s]\n",
      "Tokenizing: 100%|██████████| 4500/4500 [00:01<00:00, 3134.72text/s]\n",
      "Embedding: 100%|██████████| 4500/4500 [08:33<00:00,  8.76text/s]\n"
     ]
    }
   ],
   "source": [
    "context_embeddings = tokenizer_with_progress(df['context'].tolist())\n",
    "response_embeddings = tokenizer_with_progress(df['response'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "context_sentence_embedding = [tf.reduce_mean(embed, axis=1) for embed in context_embeddings]\n",
    "response_sentence_embedding = [tf.reduce_mean(embed, axis=1) for embed in response_embeddings]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.39950728\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "cosine_similarities = []\n",
    "for i in range(len(df)):\n",
    "    context_embedding_i = context_embeddings[i].numpy()  # Convert TensorFlow tensor to NumPy array\n",
    "    response_embedding_i = response_embeddings[i].numpy()  # Convert TensorFlow tensor to NumPy array\n",
    "    \n",
    "    # Reshape the embeddings to 2D arrays\n",
    "    context_embedding_i = context_embedding_i.reshape(1, -1)  # Reshape to a single row\n",
    "    response_embedding_i = response_embedding_i.reshape(1, -1)  # Reshape to a single row\n",
    "    \n",
    "    # Calculate cosine similarity\n",
    "    similarity = cosine_similarity(context_embedding_i, response_embedding_i)\n",
    "    cosine_similarities.append(similarity[0, 0])  # Append the similarity value\n",
    "\n",
    "print(np.mean(cosine_similarities))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kendall_tau 53.92222595160611\n"
     ]
    }
   ],
   "source": [
    "tau, _ = kendalltau(cosine_similarities, np.round(df['overall_score']).astype(int).values)\n",
    "print('kendall_tau', 50 * (1 + tau))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Combine context and response embeddings\n",
    "combined_embeddings = []\n",
    "for context_embed, response_embed in zip(context_embeddings, response_embeddings):\n",
    "    combined_embed = np.concatenate([context_embed.numpy(), response_embed.numpy()], axis=0)\n",
    "    combined_embeddings.append(combined_embed)\n",
    "\n",
    "# Apply PCA to combined embeddings\n",
    "combined_embeddings_pca = []\n",
    "for combined_embed in combined_embeddings:\n",
    "    combined_embed_2d = combined_embed.reshape(-1, combined_embed.shape[-1])  # Reshape to 2D array\n",
    "    pca = PCA(n_components=48)  # Initialize PCA with desired number of components\n",
    "    combined_embed_pca = pca.fit_transform(combined_embed_2d)  # Apply PCA\n",
    "    combined_embed_pca = combined_embed_pca[:, 1:]\n",
    "    combined_embeddings_pca.append(combined_embed_pca)\n",
    "\n",
    "# Split combined embeddings back into context and response embeddings\n",
    "context_embeddings_pca = [combined_embed_pca[:len(context_embed)] for combined_embed_pca, context_embed in zip(combined_embeddings_pca, context_embeddings)]\n",
    "response_embeddings_pca = [combined_embed_pca[len(context_embed):] for combined_embed_pca, context_embed in zip(combined_embeddings_pca, context_embeddings)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean cosine similarity after PCA: 0.30730146\n"
     ]
    }
   ],
   "source": [
    "# Calculate cosine similarity\n",
    "cosine_similarities = []\n",
    "for i in range(len(df)):\n",
    "    context_embedding_pca_i = context_embeddings_pca[i]  # PCA-transformed context embedding\n",
    "    response_embedding_pca_i = response_embeddings_pca[i]  # PCA-transformed response embedding\n",
    "    \n",
    "    # Calculate cosine similarity\n",
    "    similarity = cosine_similarity(context_embedding_pca_i, response_embedding_pca_i)\n",
    "    cosine_similarities.append(similarity[0, 0])  # Append the similarity value\n",
    "\n",
    "print(\"Mean cosine similarity after PCA:\", np.mean(cosine_similarities))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kendall_tau 50.750110842217545\n"
     ]
    }
   ],
   "source": [
    "tau, _ = kendalltau(cosine_similarities, np.round(df['overall_score']).astype(int).values)\n",
    "print('kendall_tau', 50 * (1 + tau))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/tmp/pbs.9559646.pbs/ipykernel_3700769/3457754284.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X['input'] = combined_embeddings_pca\n",
      "/var/tmp/pbs.9559646.pbs/ipykernel_3700769/3457754284.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X['similarity'] = cosine_similarities\n",
      "/var/tmp/pbs.9559646.pbs/ipykernel_3700769/3457754284.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X['overall_score'] = np.round(df['overall_score']).astype(int).values\n"
     ]
    }
   ],
   "source": [
    "X = df[['overall_score','context_id']]\n",
    "X['input'] = combined_embeddings_pca\n",
    "X['similarity'] = cosine_similarities\n",
    "X['overall_score'] = np.round(df['overall_score']).astype(int).values\n",
    "context_id = df['context_id'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_flattened = X.apply(lambda col: col['input'][0], axis=1).apply(pd.Series)\n",
    "X = pd.concat([X_flattened, X[[\"context_id\",'similarity', \"overall_score\"]]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "context_train, context_test = train_test_split(list(range(1, 501)), test_size=0.2, random_state=42)\n",
    "train = X[X['context_id'].isin(context_train)]\n",
    "test = X[X['context_id'].isin(context_test)]\n",
    "\n",
    "X_train = train.drop(columns=[\"overall_score\"])\n",
    "y_train = train[[\"overall_score\"]]\n",
    "\n",
    "X_test = test.drop(columns=[\"overall_score\"])\n",
    "y_test = test[[\"overall_score\"]]\n",
    "\n",
    "group_train = np.bincount(context_train)[1:]\n",
    "group_train = group_train*9\n",
    "group_test = np.bincount(context_test)[1:]\n",
    "group_test = group_test*9 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000959 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12495\n",
      "[LightGBM] [Info] Number of data points in the train set: 3600, number of used features: 49\n",
      "[100]\ttraining's ndcg@5: 0.976359\ttraining's kendall_tau: 74.1069\tvalid_1's ndcg@5: 0.955923\tvalid_1's kendall_tau: 51.3525\n",
      "[200]\ttraining's ndcg@5: 0.991932\ttraining's kendall_tau: 78.1057\tvalid_1's ndcg@5: 0.955773\tvalid_1's kendall_tau: 52.1468\n",
      "[300]\ttraining's ndcg@5: 0.996205\ttraining's kendall_tau: 79.8994\tvalid_1's ndcg@5: 0.955873\tvalid_1's kendall_tau: 52.3452\n",
      "[400]\ttraining's ndcg@5: 0.997889\ttraining's kendall_tau: 80.9208\tvalid_1's ndcg@5: 0.956145\tvalid_1's kendall_tau: 52.5404\n",
      "[500]\ttraining's ndcg@5: 0.99888\ttraining's kendall_tau: 81.5274\tvalid_1's ndcg@5: 0.956567\tvalid_1's kendall_tau: 52.6593\n",
      "[600]\ttraining's ndcg@5: 0.999409\ttraining's kendall_tau: 82.014\tvalid_1's ndcg@5: 0.956944\tvalid_1's kendall_tau: 52.4511\n",
      "[700]\ttraining's ndcg@5: 0.99984\ttraining's kendall_tau: 82.407\tvalid_1's ndcg@5: 0.956566\tvalid_1's kendall_tau: 52.6138\n",
      "[800]\ttraining's ndcg@5: 0.999898\ttraining's kendall_tau: 82.7217\tvalid_1's ndcg@5: 0.957415\tvalid_1's kendall_tau: 52.6768\n",
      "[900]\ttraining's ndcg@5: 0.999898\ttraining's kendall_tau: 82.9776\tvalid_1's ndcg@5: 0.95702\tvalid_1's kendall_tau: 52.7525\n",
      "[1000]\ttraining's ndcg@5: 1\ttraining's kendall_tau: 83.2181\tvalid_1's ndcg@5: 0.957305\tvalid_1's kendall_tau: 52.672\n"
     ]
    }
   ],
   "source": [
    "train_data = lgb.Dataset(X_train, label=y_train, group=group_train)\n",
    "test_data = lgb.Dataset(X_test, label=y_test, group=group_test, reference=train_data)\n",
    "\n",
    "# Define LightGBM parameters\n",
    "params = {\n",
    "    'objective': 'lambdarank',\n",
    "    'metric': 'ndcg',\n",
    "    'ndcg_at': [5],\n",
    "    'learning_rate': 0.01,\n",
    "    'boosting': 'gbdt',\n",
    "    'verbose': 1\n",
    "}\n",
    "\n",
    "\n",
    "ranker = lgb.train(params, train_data, valid_sets=[train_data, test_data], \n",
    "                   num_boost_round=1000, feval=kendall_tau, callbacks=[lgb.log_evaluation(period=100)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83.21809119899513\n",
      "52.67197666191091\n"
     ]
    }
   ],
   "source": [
    "y_pred_train = ranker.predict(X_train)\n",
    "y_pred_test = ranker.predict(X_test)\n",
    "\n",
    "tau, _ = kendalltau(y_train, y_pred_train)\n",
    "acc = 50 * (1 + tau)\n",
    "print(acc)\n",
    "\n",
    "tau, _ = kendalltau(y_test, y_pred_test)\n",
    "acc = 50 * (1 + tau)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.reset_index(drop=True, inplace=True)\n",
    "acc_list = []\n",
    "for id in context_test:\n",
    "    test_subset = test[test['context_id'] == id]\n",
    "    X_subset = test_subset.drop(columns=[\"overall_score\"])\n",
    "    y_subset = test_subset[[\"overall_score\"]]\n",
    "\n",
    "    y_pred_subset = ranker.predict(X_subset)\n",
    "\n",
    "    # Calculate accuracy using Kendall's Tau\n",
    "    tau, _ = kendalltau(y_subset, y_pred_subset)\n",
    "    acc = 50 * (1 + tau)\n",
    "    acc_list.append(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "53.09149901666611"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.nanmean(acc_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenizer and word emnedding (combine the context and response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenizing: 100%|██████████| 4500/4500 [00:03<00:00, 1144.22text/s]\n",
      "Embedding: 100%|██████████| 4500/4500 [08:46<00:00,  8.55text/s]\n"
     ]
    }
   ],
   "source": [
    "context_response_embeddings = tokenizer_with_progress(df['context_response'].tolist())\n",
    "bert_features = [tf.reduce_mean(embed, axis=1) for embed in context_response_embeddings]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text_data = df['context_response'].tolist()\n",
    "y = np.round(df['overall_score']).astype(int).values\n",
    "context_id = df['context_id'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_features_2d = np.array(bert_features).reshape(4500, 768)\n",
    "columns = [f'col{i+1}' for i in range(bert_features_2d.shape[1])]\n",
    "X = pd.DataFrame(bert_features_2d, columns=columns)\n",
    "X['overall_score'] = y\n",
    "X['context_id'] = context_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Control for fix effect (ignore first)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "from patsy import dmatrices\n",
    "\n",
    "cols_to_include = [col for col in X.columns if col.startswith('col')]\n",
    "formula = ' + '.join(cols_to_include)\n",
    "formula = 'overall_score ~ C(context_id) + ' + formula\n",
    "\n",
    "# Fit a fixed-effects model with train_id as a fixed effect\n",
    "model = sm.OLS.from_formula(formula, data=X)\n",
    "result = model.fit()\n",
    "\n",
    "# Print the summary of the model\n",
    "# print(result.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "fixed_effect = result.params.filter(like='C(context_id)')\n",
    "fixed_effect = fixed_effect.to_list()\n",
    "# print(len(fixed_effect))\n",
    "fixed_effect = [0] + fixed_effect\n",
    "fixed_effect = [effect for effect in fixed_effect for _ in range(9)]\n",
    "# print(len(fixed_effect))\n",
    "X['fixed_effect'] = fixed_effect\n",
    "X['adjust_score'] = X['fixed_effect'] + X['overall_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "X['adjust_score'] = np.round(X['adjust_score']).astype(int).values\n",
    "min_num = X['adjust_score'].min()\n",
    "if min_num < 0:\n",
    "    X['adjust_score'] = X['adjust_score'] - min_num"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "context_train, context_test = train_test_split(list(range(1, 501)), test_size=0.2, random_state=42)\n",
    "train = X[X['context_id'].isin(context_train)]\n",
    "test = X[X['context_id'].isin(context_test)]\n",
    "\n",
    "X_train = train.drop(columns=[\"overall_score\"])\n",
    "y_train = train[[\"overall_score\"]]\n",
    "\n",
    "X_test = test.drop(columns=[\"overall_score\"])\n",
    "y_test = test[[\"overall_score\"]]\n",
    "\n",
    "group_train = np.bincount(context_train)[1:]\n",
    "group_train = group_train*9 \n",
    "group_test = np.bincount(context_test)[1:]\n",
    "group_test = group_test*9 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011484 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 196095\n",
      "[LightGBM] [Info] Number of data points in the train set: 3600, number of used features: 769\n",
      "[500]\ttraining's ndcg@5: 0.998863\ttraining's kendall_tau: 83.099\tvalid_1's ndcg@5: 0.969937\tvalid_1's kendall_tau: 57.851\n",
      "[1000]\ttraining's ndcg@5: 0.999106\ttraining's kendall_tau: 84.2861\tvalid_1's ndcg@5: 0.971165\tvalid_1's kendall_tau: 58.5987\n",
      "[1500]\ttraining's ndcg@5: 0.999106\ttraining's kendall_tau: 84.8325\tvalid_1's ndcg@5: 0.971834\tvalid_1's kendall_tau: 58.9596\n",
      "[2000]\ttraining's ndcg@5: 0.999106\ttraining's kendall_tau: 85.1606\tvalid_1's ndcg@5: 0.970895\tvalid_1's kendall_tau: 59.0775\n",
      "[2500]\ttraining's ndcg@5: 0.999106\ttraining's kendall_tau: 85.4071\tvalid_1's ndcg@5: 0.971863\tvalid_1's kendall_tau: 59.2136\n",
      "[3000]\ttraining's ndcg@5: 0.999106\ttraining's kendall_tau: 85.5807\tvalid_1's ndcg@5: 0.971602\tvalid_1's kendall_tau: 59.2636\n"
     ]
    }
   ],
   "source": [
    "train_data = lgb.Dataset(X_train, label=y_train, group=group_train)\n",
    "test_data = lgb.Dataset(X_test, label=y_test, group=group_test, reference=train_data)\n",
    "\n",
    "def kendall_tau(preds, train_data):\n",
    "    y_true = train_data.get_label()\n",
    "    tau, _ = kendalltau(y_true, preds)\n",
    "    return 'kendall_tau', 50 * (1 + tau), True\n",
    "\n",
    "\n",
    "# Define LightGBM parameters\n",
    "params = {\n",
    "    'objective': 'lambdarank',\n",
    "    'metric': 'ndcg',\n",
    "    'ndcg_at': [5],\n",
    "    'learning_rate': 0.01,\n",
    "    'boosting': 'gbdt',\n",
    "    'verbose': 1\n",
    "}\n",
    "\n",
    "\n",
    "ranker = lgb.train(params, train_data, valid_sets=[train_data, test_data], \n",
    "                   num_boost_round=3000, feval=kendall_tau, callbacks=[lgb.log_evaluation(period=500)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85.58066027077025\n",
      "59.263605696977265\n"
     ]
    }
   ],
   "source": [
    "y_pred_train = ranker.predict(X_train)\n",
    "y_pred_test = ranker.predict(X_test)\n",
    "\n",
    "tau, _ = kendalltau(y_train, y_pred_train)\n",
    "acc = 50 * (1 + tau)\n",
    "print(acc)\n",
    "\n",
    "tau, _ = kendalltau(y_test, y_pred_test)\n",
    "acc = 50 * (1 + tau)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.reset_index(drop=True, inplace=True)\n",
    "acc_list = []\n",
    "for id in context_test:\n",
    "    test_subset = test[test['context_id'] == id]\n",
    "    X_subset = test_subset.drop(columns=[\"overall_score\"])\n",
    "    y_subset = test_subset[[\"overall_score\"]]\n",
    "\n",
    "    y_pred_subset = ranker.predict(X_subset)\n",
    "\n",
    "    # Calculate accuracy using Kendall's Tau\n",
    "    tau, _ = kendalltau(y_subset, y_pred_subset)\n",
    "    acc = 50 * (1 + tau)\n",
    "    acc_list.append(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "63.87148979822759"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.nanmean(acc_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/tmp/pbs.9560567.pbs/ipykernel_4138335/179227380.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train.rename(columns={col: str(col) for col in train.columns}, inplace=True)\n",
      "/var/tmp/pbs.9560567.pbs/ipykernel_4138335/179227380.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test.rename(columns={col: str(col) for col in test.columns}, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "context_train, context_test = train_test_split(list(range(1, 501)), test_size=0.2, random_state=42)\n",
    "train = X[X['context_id'].isin(context_train)]\n",
    "test = X[X['context_id'].isin(context_test)]\n",
    "\n",
    "train.rename(columns={col: str(col) for col in train.columns}, inplace=True)\n",
    "test.rename(columns={col: str(col) for col in test.columns}, inplace=True)\n",
    "\n",
    "\n",
    "X_train = train.drop(columns=[\"overall_score\"])\n",
    "y_train = train[[\"overall_score\"]]\n",
    "\n",
    "X_test = test.drop(columns=[\"overall_score\"])\n",
    "y_test = test[[\"overall_score\"]]\n",
    "\n",
    "group_train = np.bincount(context_train)[1:]\n",
    "group_train = group_train*9 \n",
    "group_test = np.bincount(context_test)[1:]\n",
    "group_test = group_test*9 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Standardize the feature columns separately for the training and testing sets\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = X_train.drop(columns=[\"context_id\"])\n",
    "X_test_scaled = X_test.drop(columns=[\"context_id\"])\n",
    "X_train_scaled = scaler.fit_transform(X_train_scaled)\n",
    "X_test_scaled = scaler.transform(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of components explaining 70% variance: 39\n"
     ]
    }
   ],
   "source": [
    "# Check how many PCA can explain 80% of the data\n",
    "pca = PCA()\n",
    "X_train_pca = pca.fit_transform(X_train_scaled)\n",
    "\n",
    "# Calculate explained variance ratio\n",
    "explained_variance_ratio = pca.explained_variance_ratio_\n",
    "cumulative_explained_variance = np.cumsum(explained_variance_ratio)\n",
    "\n",
    "# Find the number of components\n",
    "n_components_70 = np.argmax(cumulative_explained_variance >= 0.7) + 1\n",
    "\n",
    "# Plot \n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.plot(range(1, len(cumulative_explained_variance) + 1), cumulative_explained_variance, marker='o', linestyle='-')\n",
    "plt.xlabel('Number of Principal Components')\n",
    "plt.ylabel('Cumulative Explained Variance')\n",
    "plt.title('Cumulative Explained Variance')\n",
    "plt.axvline(x=n_components_70, color='r', linestyle='--', label=f'{n_components_70} components (70% variance)')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Number of components explaining 70% variance: {n_components_70}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply PCA only to the standardized feature columns\n",
    "pca = PCA(n_components=39)  # Adjust the number of components as needed\n",
    "X_train_pca = pd.DataFrame(pca.fit_transform(X_train_scaled))\n",
    "X_test_pca = pd.DataFrame(pca.transform(X_test_scaled))\n",
    "\n",
    "X_train.reset_index(drop=True, inplace=True)\n",
    "X_train_pca = pd.concat([X_train_pca, X_train['context_id']], axis=1)\n",
    "\n",
    "X_test.reset_index(drop=True, inplace=True)\n",
    "X_test_pca = pd.concat([X_test_pca, X_test['context_id']], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_pca_dropped = X_train_pca.drop(X_train_pca.columns[0], axis=1)\n",
    "X_test_pca_dropped = X_test_pca.drop(X_test_pca.columns[0], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_data = X_train_pca_dropped\n",
    "x_test_data = X_test_pca_dropped\n",
    "\n",
    "\n",
    "train_data = lgb.Dataset(x_train_data, label=y_train, group=group_train)\n",
    "test_data = lgb.Dataset(x_test_data, label=y_test, group=group_test, reference=train_data)\n",
    "\n",
    "def kendall_tau(preds, train_data):\n",
    "    y_true = train_data.get_label()\n",
    "    tau, _ = kendalltau(y_true, preds)\n",
    "    return 'kendall_tau', 50 * (1 + tau), True\n",
    "\n",
    "# Define LightGBM parameters\n",
    "params = {\n",
    "    'objective': 'lambdarank',\n",
    "    'metric': 'ndcg',\n",
    "    'ndcg_at': [5],\n",
    "    'learning_rate': 0.01,\n",
    "    'boosting': 'gbdt',\n",
    "    'lambda_l1': 0.3, \n",
    "    'lambda_l2': 0.1, \n",
    "    'verbose': 1\n",
    "}\n",
    "\n",
    "ranker = lgb.train(params, train_data, valid_sets=[train_data, test_data], num_boost_round=3000, feval=kendall_tau, callbacks=[lgb.log_evaluation(period=500)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80.17971834631001\n",
      "56.72362930980446\n"
     ]
    }
   ],
   "source": [
    "y_pred_train = ranker.predict(x_train_data)\n",
    "y_pred_test = ranker.predict(x_test_data)\n",
    "\n",
    "tau, _ = kendalltau(y_train, y_pred_train)\n",
    "acc = 50 * (1 + tau)\n",
    "print(acc)\n",
    "\n",
    "tau, _ = kendalltau(y_test, y_pred_test)\n",
    "acc = 50 * (1 + tau)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.reset_index(drop=True, inplace=True)\n",
    "acc_list = []\n",
    "for id in context_test:\n",
    "    test_subset = test[test['context_id'] == id]\n",
    "    X_subset = test_subset.drop(columns=[\"overall_score\", \"context_id\"])\n",
    "    X_subset_scaled = scaler.transform(X_subset)    \n",
    "    X_subset_pca = pca.transform(X_subset_scaled)\n",
    "    X_subset_pca = pd.DataFrame(X_subset_pca)\n",
    "    X_subset_pca[\"context_id\"] = [id]*len(X_subset_pca)\n",
    "    X_subset_pca_dropped = X_subset_pca.drop(columns=[0])\n",
    "    y_subset = test_subset[[\"overall_score\"]]\n",
    "\n",
    "    y_pred_subset = ranker.predict(X_subset_pca_dropped)\n",
    "   \n",
    "    # Calculate accuracy using Kendall's Tau\n",
    "    tau, _ = kendalltau(y_subset, y_pred_subset)\n",
    "    acc = 50 * (1 + tau)\n",
    "    acc_list.append(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "61.24865752363682"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.nanmean(acc_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imput as a vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context_id</th>\n",
       "      <th>context_response</th>\n",
       "      <th>overall_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>[17 weeks if im not mistaken. then the playoff...</td>\n",
       "      <td>[4.0, 3.75, 3.0, 3.75, 3.75, 3.5, 4.25, 4.5, 3.5]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>[18 holes a games. Seems like a long day.\\nYea...</td>\n",
       "      <td>[3.75, 4.25, 4.0, 4.5, 3.5, 4.25, 3.0, 2.5, 3.75]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>[222-0. I dont even see how that is possible. ...</td>\n",
       "      <td>[3.0, 4.5, 2.5, 1.25, 4.5, 1.5, 1.0, 4.75, 3.25]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>[300 of them? that sounds impressive and too b...</td>\n",
       "      <td>[3.25, 4.25, 3.75, 4.0, 3.5, 4.5, 2.75, 3.75, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>[A Mars colonization project planned for 2023 ...</td>\n",
       "      <td>[3.5, 4.0, 4.5, 4.0, 3.0, 3.75, 2.25, 4.0, 2.75]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   context_id                                   context_response  \\\n",
       "0           1  [17 weeks if im not mistaken. then the playoff...   \n",
       "1           2  [18 holes a games. Seems like a long day.\\nYea...   \n",
       "2           3  [222-0. I dont even see how that is possible. ...   \n",
       "3           4  [300 of them? that sounds impressive and too b...   \n",
       "4           5  [A Mars colonization project planned for 2023 ...   \n",
       "\n",
       "                                       overall_score  \n",
       "0  [4.0, 3.75, 3.0, 3.75, 3.75, 3.5, 4.25, 4.5, 3.5]  \n",
       "1  [3.75, 4.25, 4.0, 4.5, 3.5, 4.25, 3.0, 2.5, 3.75]  \n",
       "2   [3.0, 4.5, 2.5, 1.25, 4.5, 1.5, 1.0, 4.75, 3.25]  \n",
       "3  [3.25, 4.25, 3.75, 4.0, 3.5, 4.5, 2.75, 3.75, ...  \n",
       "4   [3.5, 4.0, 4.5, 4.0, 3.0, 3.75, 2.25, 4.0, 2.75]  "
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_grouped = df.groupby('context_id').agg({\n",
    "    'context_response': list, \n",
    "    'overall_score': list\n",
    "}).reset_index()\n",
    "data_grouped.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RankingModel(tf.keras.Model):\n",
    "    def __init__(self, num_outputs, bert_trainable=False):\n",
    "        super(RankingModel, self).__init__()\n",
    "        self.bert = TFBertModel.from_pretrained('bert-base-uncased')\n",
    "        self.bert.trainable = bert_trainable\n",
    "        self.dense = Dense(num_outputs, activation='linear')\n",
    "\n",
    "    def call(self, inputs):\n",
    "        bert_output = self.bert(inputs)[0][:, 0, :]\n",
    "        output = self.dense(bert_output)\n",
    "        return output\n",
    "\n",
    "def custom_loss(true_labels, output):\n",
    "    return 1 - tf.reduce_mean(tf.keras.losses.cosine_similarity(true_labels, output))\n",
    "\n",
    "def train_model(data, true_labels, epochs, lr, bert_trainable=False):\n",
    "    tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "    model = RankingModel(num_outputs=1, bert_trainable=bert_trainable)\n",
    "    optimizer = Adam(lr=lr)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        for i in tqdm(range(len(data)), desc=f'Epoch {epoch+1}/{epochs}', unit='batch'):\n",
    "            with tf.GradientTape() as tape:\n",
    "                input_ids = []\n",
    "                for sentence in data[i]:\n",
    "                    encoded = tokenizer.encode(\n",
    "                        sentence,\n",
    "                        add_special_tokens=True,\n",
    "                        max_length=128,\n",
    "                        truncation=True,\n",
    "                        padding='max_length',\n",
    "                        return_tensors='tf'\n",
    "                    )\n",
    "                    input_ids.append(encoded)\n",
    "                input_ids = tf.concat(input_ids, axis=0)\n",
    "                labels = tf.constant([true_labels[i]], dtype=tf.float32)\n",
    "                outputs = model(input_ids)\n",
    "                loss = custom_loss(labels, outputs)\n",
    "                grads = tape.gradient(loss, model.trainable_variables)\n",
    "                optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "                total_loss += loss\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Loss: {total_loss/len(data)}\")\n",
    "\n",
    "    return model\n",
    "\n",
    "def predict_scores(model, data):\n",
    "    tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "    predictions = []\n",
    "\n",
    "    for i in range(len(data)):\n",
    "        input_ids = []\n",
    "        for sentence in data[i]:\n",
    "            encoded = tokenizer.encode(\n",
    "                sentence,\n",
    "                add_special_tokens=True,\n",
    "                max_length=128,\n",
    "                truncation=True,\n",
    "                padding='max_length',\n",
    "                return_tensors='tf'\n",
    "            )\n",
    "            input_ids.append(encoded)\n",
    "        input_ids = tf.concat(input_ids, axis=0)\n",
    "        outputs = model(input_ids)\n",
    "        predictions.append(outputs.numpy().flatten())\n",
    "\n",
    "    return predictions\n",
    "\n",
    "def calculate_kendall_tau(true_labels, predicted_scores):\n",
    "    tau_list = []\n",
    "\n",
    "    for true, pred in zip(true_labels, predicted_scores):\n",
    "        tau, _ = kendalltau(true, pred)\n",
    "        tau_list.append(50*(1+tau))\n",
    "\n",
    "    return tau_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFBertModel were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n",
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n",
      "Epoch 1/5: 100%|██████████| 80/80 [00:23<00:00,  3.44batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Loss: -1.9418901205062866\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5: 100%|██████████| 80/80 [00:23<00:00,  3.47batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/5, Loss: -1.9584420919418335\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5: 100%|██████████| 80/80 [00:23<00:00,  3.47batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/5, Loss: -1.9584420919418335\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5:  79%|███████▉  | 63/80 [00:18<00:04,  3.48batch/s]"
     ]
    }
   ],
   "source": [
    "data = data_grouped[\"context_response\"].tolist()\n",
    "true_labels = data_grouped[\"overall_score\"].tolist()\n",
    "\n",
    "#### For test\n",
    "data = data[:100]\n",
    "true_labels = true_labels[:100]\n",
    "data_train, data_test, labels_train, labels_test = train_test_split(data, true_labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "model = train_model(data_train, labels_train, epochs=3, lr=0.01, bert_trainable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kendall's Tau: [39.84547006925096, 60.476975951561876, 42.26269424262284, 46.549672203288225, 75.72478777137633, 32.85014148574912, 38.21488698022421, 31.666666666666664, 63.055824196677335, 55.89255650988789, 70.00816826662603, 48.503289149776876, 42.74676433517926, 36.0728496367211, 21.56249384576064, 60.154529930749035, 39.84547006925096, 44.28338049524971, 48.54935286703585, 70.00816826662603]\n"
     ]
    }
   ],
   "source": [
    "# Predict scores using the trained model\n",
    "predicted_scores = predict_scores(model, data_test)\n",
    "kendall_tau = calculate_kendall_tau(labels_test, predicted_scores)\n",
    "print(\"Kendall's Tau:\", kendall_tau)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48.41370714701405"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(kendall_tau)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tf2_env]",
   "language": "python",
   "name": "conda-env-tf2_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
